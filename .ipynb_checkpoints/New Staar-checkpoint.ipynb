{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f468be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'new_data'...\n",
      "Updating files:  39% (1306/3266)\n",
      "Updating files:  40% (1307/3266)\n",
      "Updating files:  41% (1340/3266)\n",
      "Updating files:  42% (1372/3266)\n",
      "Updating files:  43% (1405/3266)\n",
      "Updating files:  44% (1438/3266)\n",
      "Updating files:  45% (1470/3266)\n",
      "Updating files:  46% (1503/3266)\n",
      "Updating files:  47% (1536/3266)\n",
      "Updating files:  48% (1568/3266)\n",
      "Updating files:  49% (1601/3266)\n",
      "Updating files:  50% (1633/3266)\n",
      "Updating files:  51% (1666/3266)\n",
      "Updating files:  52% (1699/3266)\n",
      "Updating files:  53% (1731/3266)\n",
      "Updating files:  54% (1764/3266)\n",
      "Updating files:  55% (1797/3266)\n",
      "Updating files:  56% (1829/3266)\n",
      "Updating files:  57% (1862/3266)\n",
      "Updating files:  58% (1895/3266)\n",
      "Updating files:  59% (1927/3266)\n",
      "Updating files:  60% (1960/3266)\n",
      "Updating files:  61% (1993/3266)\n",
      "Updating files:  62% (2025/3266)\n",
      "Updating files:  63% (2058/3266)\n",
      "Updating files:  64% (2091/3266)\n",
      "Updating files:  65% (2123/3266)\n",
      "Updating files:  66% (2156/3266)\n",
      "Updating files:  67% (2189/3266)\n",
      "Updating files:  68% (2221/3266)\n",
      "Updating files:  68% (2235/3266)\n",
      "Updating files:  69% (2254/3266)\n",
      "Updating files:  70% (2287/3266)\n",
      "Updating files:  71% (2319/3266)\n",
      "Updating files:  72% (2352/3266)\n",
      "Updating files:  73% (2385/3266)\n",
      "Updating files:  74% (2417/3266)\n",
      "Updating files:  75% (2450/3266)\n",
      "Updating files:  76% (2483/3266)\n",
      "Updating files:  77% (2515/3266)\n",
      "Updating files:  78% (2548/3266)\n",
      "Updating files:  79% (2581/3266)\n",
      "Updating files:  80% (2613/3266)\n",
      "Updating files:  81% (2646/3266)\n",
      "Updating files:  82% (2679/3266)\n",
      "Updating files:  83% (2711/3266)\n",
      "Updating files:  84% (2744/3266)\n",
      "Updating files:  85% (2777/3266)\n",
      "Updating files:  86% (2809/3266)\n",
      "Updating files:  87% (2842/3266)\n",
      "Updating files:  88% (2875/3266)\n",
      "Updating files:  89% (2907/3266)\n",
      "Updating files:  90% (2940/3266)\n",
      "Updating files:  91% (2973/3266)\n",
      "Updating files:  92% (3005/3266)\n",
      "Updating files:  93% (3038/3266)\n",
      "Updating files:  94% (3071/3266)\n",
      "Updating files:  94% (3073/3266)\n",
      "Updating files:  95% (3103/3266)\n",
      "Updating files:  96% (3136/3266)\n",
      "Updating files:  97% (3169/3266)\n",
      "Updating files:  98% (3201/3266)\n",
      "Updating files:  99% (3234/3266)\n",
      "Updating files: 100% (3266/3266)\n",
      "Updating files: 100% (3266/3266), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Satyam-Nayak/New-STAAR.git new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f27eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Welcome\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c79fc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\welcome\\anaconda3\\lib\\site-packages (2.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db318aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca28736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import keras.optimizers\n",
    "from sklearn.metrics import classification_report\n",
    "import keras.optimizers\n",
    "from keras.applications import vgg16\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b76d914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary constants\n",
    "TEST_DIR = '/content/Brain-Tumor-Classification-DataSet/Testing'\n",
    "TRAIN_DIR = '/content/Brain-Tumor-Classification-DataSet/Training'\n",
    "IMG_SIZE = 224\n",
    "CATEGORIES = [\"glioma_tumor\",\"meningioma_tumor\",\"no_tumor\",\"pituitary_tumor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f20300c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/path/to/your/training/dataset\\\\category1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m             new_array \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img_array, (IMG_SIZE, IMG_SIZE))\n\u001b[0;32m     24\u001b[0m             training_data\u001b[38;5;241m.\u001b[39mappend([new_array, class_num])\n\u001b[1;32m---> 26\u001b[0m \u001b[43mcreate_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Shuffle the training data\u001b[39;00m\n\u001b[0;32m     29\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(training_data)\n",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m, in \u001b[0;36mcreate_training_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TRAIN_DIR, category)\n\u001b[0;32m     20\u001b[0m class_num \u001b[38;5;241m=\u001b[39m CATEGORIES\u001b[38;5;241m.\u001b[39mindex(category)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     22\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, img), cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m     23\u001b[0m     new_array \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img_array, (IMG_SIZE, IMG_SIZE))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/path/to/your/training/dataset\\\\category1'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your dataset directory and categories\n",
    "TRAIN_DIR = '/path/to/your/training/dataset'  # Replace with the actual path\n",
    "CATEGORIES = ['category1', 'category2', 'category3']  # Replace with your category names\n",
    "\n",
    "# Other constants\n",
    "IMG_SIZE = 100  # Adjust this to the desired image size\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(TRAIN_DIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "            training_data.append([new_array, class_num])\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "# Shuffle the training data\n",
    "random.shuffle(training_data)\n",
    "\n",
    "print(len(training_data))\n",
    "\n",
    "print(\"train\")\n",
    "print()\n",
    "\n",
    "X_train = np.array([i[0] for i in training_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "Y_train = [i[1] for i in training_data]\n",
    "\n",
    "# Save the training data to pickle files\n",
    "with open(\"X_train.pickle\", \"wb\") as pickle_out:\n",
    "    pickle.dump(X_train, pickle_out)\n",
    "\n",
    "with open(\"Y_train.pickle\", \"wb\") as pickle_out:\n",
    "    pickle.dump(Y_train, pickle_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d08d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
